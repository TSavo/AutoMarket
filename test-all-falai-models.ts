/**
 * Test All fal.ai Model Implementations
 * 
 * Complete test suite demonstrating all 5 model types implemented for fal.ai
 */

import { FalAiProvider } from './src/media/providers/falai/FalAiProvider';
import { Text, Image, Video, Audio } from './src/media/assets/roles';
import { SmartAssetFactory } from './src/media/assets/SmartAssetFactory';

async function testAllFalAiModels() {
  console.log('ğŸš€ Testing ALL fal.ai Model Implementations');
  console.log('==============================================');

  // Configure fal.ai provider
  const provider = new FalAiProvider();
  await provider.configure({
    apiKey: process.env.FALAI_API_KEY || 'fal_demo_key',
    discovery: {
      openRouterApiKey: process.env.OPENROUTER_API_KEY, // For FREE model categorization
      cacheDir: './cache',
      maxCacheAge: 24 * 60 * 60 * 1000 // 24 hours
    }
  });

  if (!await provider.isAvailable()) {
    console.log('âŒ fal.ai provider not available');
    return;
  }

  console.log('âœ… fal.ai provider connected');

  try {
    // Test 1: Text-to-Image (FLUX Pro)
    console.log('\nğŸ¨ Test 1: Text-to-Image Generation (FLUX Pro)');
    console.log('================================================');
    
    const textToImageModel = await provider.createTextToImageModel('fal-ai/flux-pro');
    console.log(`âœ… Created model: ${textToImageModel.getDisplayName()}`);
    
    const promptText = Text.fromString('a futuristic cityscape at sunset with flying cars, cyberpunk style, highly detailed');
    console.log(`ğŸ“ Prompt: "${promptText.content}"`);
    
    const generatedImage = await textToImageModel.transform(promptText, {
      width: 1024,
      height: 1024,
      steps: 28,
      guidanceScale: 7.5,
      quality: 'high'
    });
    
    console.log(`âœ… Generated image: ${generatedImage.getDimensions()?.width}x${generatedImage.getDimensions()?.height}, ${generatedImage.getHumanSize()}`);
    console.log(`ğŸ“ Saved to: ${generatedImage.metadata?.localPath}`);

    // Test 2: Text-to-Video (Runway Gen3)
    console.log('\nğŸ¬ Test 2: Text-to-Video Generation (Runway Gen3)');
    console.log('=================================================');
    
    const textToVideoModel = await provider.createTextToVideoModel('fal-ai/runway-gen3');
    console.log(`âœ… Created model: ${textToVideoModel.getDisplayName()}`);
    
    const videoPromptText = Text.fromString('a serene ocean wave crashing on a sandy beach, golden hour lighting, slow motion');
    console.log(`ğŸ“ Prompt: "${videoPromptText.content}"`);
    
    const generatedVideo = await textToVideoModel.transform(videoPromptText, {
      duration: 4,
      aspectRatio: '16:9',
      fps: 30,
      motionStrength: 0.7
    });
    
    console.log(`âœ… Generated video: ${generatedVideo.getDuration()}s, ${JSON.stringify(generatedVideo.getDimensions())}`);
    console.log(`ğŸ“ Saved to: ${generatedVideo.metadata?.localPath}`);

    // Test 3: Image-to-Video (FramePack)
    console.log('\nğŸ–¼ï¸â†’ğŸ¬ Test 3: Image-to-Video Animation (FramePack)');
    console.log('================================================');
    
    const imageToVideoModel = await provider.createImageToVideoModel('fal-ai/framepack');
    console.log(`âœ… Created model: ${imageToVideoModel.getDisplayName()}`);
    
    console.log(`ğŸ”„ Using generated image from Test 1 as input...`);
    
    const animatedVideo = await imageToVideoModel.transform(generatedImage, {
      duration: 3,
      fps: 25,
      motionStrength: 0.5,
      loop: false,
      interpolationSteps: 8
    });
    
    console.log(`âœ… Animated video: ${animatedVideo.getDuration()}s, ${JSON.stringify(animatedVideo.getDimensions())}`);
    console.log(`ğŸ“ Saved to: ${animatedVideo.metadata?.localPath}`);

    // Test 4: Video-to-Video (Face Swap/Enhancement)
    console.log('\nğŸ­ Test 4: Video-to-Video Processing (Enhancement)');
    console.log('=================================================');
    
    const videoToVideoModel = await provider.createVideoToVideoModel('fal-ai/video-enhance');
    console.log(`âœ… Created model: ${videoToVideoModel.getDisplayName()}`);
    
    console.log(`ğŸ”„ Using generated video from Test 2 as input...`);
    
    const enhancedVideoResult = await videoToVideoModel.transform(generatedVideo, [], {
      outputQuality: 'high',
      outputResolution: '1920x1080',
      outputFormat: 'mp4',
      codec: 'libx264'
    });
    
    console.log(`âœ… Enhanced video: ${enhancedVideoResult.composedVideo.getDuration()}s, resolution: ${enhancedVideoResult.metadata.resolution}`);
    console.log(`ğŸ“Š Processing info: ${enhancedVideoResult.metadata.overlayInfo.count} overlays processed`);
    console.log(`ğŸ“ Saved to: ${enhancedVideoResult.composedVideo.metadata?.localPath}`);

    // Test 5: Text-to-Audio (XTTS-v2)
    console.log('\nğŸ”Š Test 5: Text-to-Audio Generation (XTTS-v2)');
    console.log('=============================================');
    
    const textToAudioModel = await provider.createTextToAudioModel('fal-ai/xtts-v2');
    console.log(`âœ… Created model: ${textToAudioModel.getDisplayName()}`);
    console.log(`ğŸ¤ Voices available: ${textToAudioModel.getAvailableVoices().join(', ')}`);
    console.log(`ğŸ”„ Voice cloning supported: ${textToAudioModel.supportsVoiceCloning()}`);
    console.log(`ğŸ“ Max text length: ${textToAudioModel.getMaxTextLength()} characters`);
    
    const speechText = Text.fromString('Welcome to AutoMarket, the future of AI-powered media generation. This audio was created using fal.ai and XTTS voice synthesis technology.');
    console.log(`ğŸ“ Text: "${speechText.content}"`);
    
    const generatedAudio = await textToAudioModel.transform(speechText, {
      voice: 'female_1',
      language: 'en',
      speed: 1.0,
      quality: 'high',
      format: 'wav'
    });
    
    console.log(`âœ… Generated audio: ${generatedAudio.metadata?.duration}s, ${(generatedAudio.getSize() / 1024).toFixed(1)}KB`);
    console.log(`ğŸ“ Saved to: ${generatedAudio.metadata?.localPath}`);

    // Test 6: Image-to-Image (Real-ESRGAN Upscaling)
    console.log('\nğŸ” Test 6: Image-to-Image Processing (Real-ESRGAN Upscaling)');
    console.log('===========================================================');
    
    const imageToImageModel = await provider.createImageToImageModel('fal-ai/real-esrgan');
    console.log(`âœ… Created model: ${imageToImageModel.getDisplayName()}`);
    console.log(`ğŸ–¼ï¸  Formats supported: ${imageToImageModel.getSupportedFormats().join(', ')}`);
    
    console.log(`ğŸ”„ Using generated image from Test 1 as input for upscaling...`);
    
    const upscaledImage = await imageToImageModel.transform(generatedImage, {
      scale: 4, // 4x upscaling
      denoise: true,
      quality: 'high',
      format: 'png'
    });
    
    const originalDims = generatedImage.getDimensions();
    const upscaledDims = upscaledImage.getDimensions();
    console.log(`âœ… Upscaled image: ${originalDims?.width}x${originalDims?.height} â†’ ${upscaledDims?.width}x${upscaledDims?.height}`);
    console.log(`ğŸ“ˆ Size increase: ${generatedImage.getHumanSize()} â†’ ${upscaledImage.getHumanSize()}`);
    console.log(`ğŸ“ Saved to: ${upscaledImage.metadata?.localPath}`);

    // Summary
    console.log('\nğŸ‰ ALL FALAAI MODEL TESTS COMPLETED!');
    console.log('===================================');
    console.log('âœ… Text-to-Image: FLUX Pro generation');
    console.log('âœ… Text-to-Video: Runway Gen3 generation');
    console.log('âœ… Image-to-Video: FramePack animation');
    console.log('âœ… Video-to-Video: Video enhancement');
    console.log('âœ… Text-to-Audio: XTTS-v2 voice synthesis');
    console.log('âœ… Image-to-Image: Real-ESRGAN upscaling');
    
    console.log('\nğŸ“Š Model Performance Summary:');
    console.log(`ğŸ¨ Generated ${upscaledDims?.width}x${upscaledDims?.height} image (${upscaledImage.getHumanSize()})`);
    console.log(`ğŸ¬ Generated ${generatedVideo.getDuration()}s video (${JSON.stringify(generatedVideo.getDimensions())})`);
    console.log(`ğŸ­ Enhanced video to ${enhancedVideoResult.metadata.resolution}`);
    console.log(`ğŸ”Š Generated ${generatedAudio.metadata?.duration}s audio (${(generatedAudio.getSize() / 1024).toFixed(1)}KB)`);
    console.log(`ğŸ” Upscaled image by ${upscaledImage.getDimensions()?.width! / generatedImage.getDimensions()?.width!}x`);
    
    console.log('\nğŸ¯ fal.ai Provider Status: FULLY OPERATIONAL');
    console.log('All 5+ model categories successfully implemented and tested!');

  } catch (error) {
    console.error('âŒ Test failed:', error);
    throw error;
  }
}

// Run test if executed directly
if (require.main === module) {
  testAllFalAiModels().catch(console.error);
}

export { testAllFalAiModels };
