/**
 * Test Video Composition with Transparency and Timing
 * 
 * Tests the enhanced video composition with:
 * - Alpha channel preservation for transparency
 * - Timing controls for overlay duration
 */

import { FFMPEGVideoComposerModel } from './src/media/models/FFMPEGVideoComposerModel';
import { FFMPEGDockerService } from './src/media/services/FFMPEGDockerService';
import { FFMPEGAPIClient } from './src/media/clients/FFMPEGAPIClient';
import { SmartAssetFactory } from './src/media/assets/SmartAssetFactory';
import fs from 'fs';
import path from 'path';

async function testEnhancedVideoComposition() {
  console.log('ğŸ¬ Testing Enhanced Video Composition with Transparency and Timing...\n');

  try {
    // Initialize services
    const dockerService = new FFMPEGDockerService();
    const apiClient = new FFMPEGAPIClient({
      baseUrl: 'http://localhost:8006',
      timeout: 300000 // 5 minutes for processing
    });

    // Initialize composer model
    const composer = new FFMPEGVideoComposerModel({
      dockerService,
      apiClient
    });

    // Check service health
    const isAvailable = await composer.isAvailable();
    if (!isAvailable) {
      throw new Error('FFMPEG service is not available');
    }
    console.log('âœ… Service is healthy and available');

    // Prepare file paths
    const baseVideoPath = path.resolve('./300-million-job-massacre-goldman-sachs-avatar.mp4');
    const overlayVideoPath = path.resolve('./overlay.webm');

    console.log('ğŸ“ Base video:', baseVideoPath);
    console.log('ğŸ“ Overlay video:', overlayVideoPath);

    // Verify files exist
    if (!fs.existsSync(baseVideoPath)) {
      throw new Error('Base video file not found');
    }    if (!fs.existsSync(overlayVideoPath)) {
      throw new Error('Overlay video file not found');
    }
    
    console.log('âœ… Both video files found');

    // Load assets using smart asset factory
    console.log('\nğŸ“¦ Loading assets with smart asset factory...');
    const baseVideoAsset = SmartAssetFactory.load(baseVideoPath);
    const overlayVideoAsset = SmartAssetFactory.load(overlayVideoPath);
    console.log('âœ… Assets loaded successfully');

    // Test composition with timing controls using the model
    console.log('\nğŸ¥ Starting enhanced video composition...');
    console.log('â±ï¸  Overlay will appear from 5 seconds for 25 seconds duration');
    
    const startTime = Date.now();    // Use the model with proper options
    const result = await composer.transform(
      baseVideoAsset,
      overlayVideoAsset,
      {
        overlayStartTime: 5,     // Start at 5 seconds
        overlayDuration: 25,     // Show for 25 seconds
        position: 'bottom-right',
        opacity: 1.0,            // Full opacity (transparency comes from WebM alpha)
        overlayWidth: '25%',     // 25% of base video width
        overlayHeight: '25%',    // 25% of base video height
        outputFormat: 'mp4',
        codec: 'h264_nvenc'         // Use CPU codec temporarily to test filter logic
      }
    );

    const endTime = Date.now();
    const processingTime = (endTime - startTime) / 1000;

    console.log('\nğŸ‰ Enhanced composition completed!');
    console.log('ğŸ“Š Results:');
    console.log(`   â±ï¸  Processing time: ${processingTime.toFixed(1)} seconds`);
    console.log(`   ï¿½ Resolution: ${result.metadata.resolution}`);
    console.log(`   â³ Duration: ${result.metadata.duration.toFixed(1)} seconds`);
    console.log(`   ğŸ“ Aspect ratio: ${result.metadata.aspectRatio}`);
    console.log(`   ğŸ¬ Framerate: ${result.metadata.framerate} fps`);

    console.log('\nâœ¨ New Features Applied:');
    console.log('   ğŸ” Alpha channel preservation for transparency');
    console.log(`   â±ï¸  Overlay timing: appears from ${result.metadata.overlayInfo.startTime}s for ${result.metadata.overlayInfo.duration}s`);
    console.log(`   ğŸ“ Position: ${result.metadata.overlayInfo.position}`);
    console.log(`   ğŸ“ Overlay size: ${result.metadata.overlayInfo.finalSize.width}x${result.metadata.overlayInfo.finalSize.height}`);
    console.log('   ğŸ¯ Enhanced pixel format for web compatibility');
    console.log('   ğŸš€ Fast start enabled for streaming');    console.log('\nğŸ’¡ You can now view the enhanced composition with proper transparency and timing!');
    console.log('ğŸ’¾ The composed video is available in the result.composedVideo asset');

    // Save the composed video to disk
    console.log('\nğŸ’¾ Saving composed video to disk...');
    const outputPath = path.resolve('./result-enhanced-composition.mp4');
    
    try {
      fs.writeFileSync(outputPath, result.composedVideo.data);
      const fileSizeMB = (result.composedVideo.data.length / (1024 * 1024)).toFixed(2);
      console.log('âœ… Video saved successfully!');
      console.log(`   ğŸ“ Output path: ${outputPath}`);
      console.log(`   ğŸ“Š File size: ${fileSizeMB} MB`);
    } catch (saveError) {
      console.error('âŒ Failed to save video to disk:', saveError.message);
    }

  } catch (error) {
    console.error('âŒ Enhanced composition failed:', error.message);
    
    if (error.message.includes('ECONNREFUSED')) {
      console.log('\nğŸ’¡ Make sure the FFmpeg service is running:');
      console.log('   cd services/ffmpeg && npm run dev');
    }
  }
}

// Run the enhanced test
testEnhancedVideoComposition().catch(console.error);
